{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\gabri\\Documents\\Twitter_Username.txt\", 'r') as file_1:\n",
    "    username = file_1.read()\n",
    "\n",
    "with open(r\"C:\\Users\\gabri\\Documents\\Twitter_Password.txt\", 'r') as file_2:\n",
    "    password = file_2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweets = 100\n",
    "topic = 'CIBC'\n",
    "output = r\"C:\\Users\\gabri\\Documents\\tweets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_down(browser):\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_twitter_search():\n",
    "    with webdriver.Chrome(options=options) as browser:\n",
    "        url = 'https://twitter.com/'\n",
    "        browser.get(url)\n",
    "\n",
    "        wait = WebDriverWait(browser, 50)\n",
    "\n",
    "        login_button = wait.until(EC.presence_of_element_located((By.XPATH, '//a[@href=\"/login\"]')))\n",
    "        browser.execute_script(\"arguments[0].scrollIntoView(true);\", login_button)\n",
    "        time.sleep(2)\n",
    "        login_button.click()\n",
    "\n",
    "        username_input = wait.until(EC.presence_of_element_located((By.XPATH, './/input[@name=\"text\"]')))\n",
    "        username_input.send_keys(username)\n",
    "        username_input.send_keys(Keys.RETURN)\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        password_input = wait.until(EC.presence_of_element_located((By.XPATH, './/input[@name=\"password\"]')))\n",
    "        password_input.send_keys(password)\n",
    "        password_input.send_keys(Keys.RETURN)\n",
    "\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, '//a[@href=\"/explore\"]'))).click()\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, '//input[@enterkeyhint=\"search\"]')))\n",
    "\n",
    "        search_input = browser.find_element(By.XPATH, '//input[@enterkeyhint=\"search\"]')\n",
    "        search_input.send_keys(topic)\n",
    "        search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "        current_tweets = 0\n",
    "        user_data = []\n",
    "        text_data = []\n",
    "        time_data = []\n",
    "\n",
    "        while current_tweets < max_tweets:\n",
    "\n",
    "            for _ in range(5):\n",
    "                scroll_down(browser)\n",
    "\n",
    "            tweets = wait.until(EC.presence_of_all_elements_located((By.XPATH, '//article[@role=\"article\"]')))\n",
    "\n",
    "            for tweet in tweets:\n",
    "                try:\n",
    "                    user = tweet.find_element(By.XPATH, './/span[contains(text(), \"@\")]').text\n",
    "                    text = tweet.find_element(By.XPATH, \".//div[@lang]\").text\n",
    "                    tweet_time = tweet.find_element(By.XPATH, \".//time\").get_attribute(\"datetime\")\n",
    "\n",
    "                    tweets_data = [user, text, tweet_time]\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting tweet: {e}\")\n",
    "                    tweets_data = ['user', 'text', \"time\"]\n",
    "\n",
    "                user_data.append(tweets_data[0])\n",
    "                text_data.append(\" \".join(tweets_data[1].split()))\n",
    "                time_data.append(tweets_data[2])\n",
    "\n",
    "                current_tweets += 1\n",
    "\n",
    "            print(f\"Scraped {current_tweets} tweets\")\n",
    "\n",
    "            if current_tweets >= max_tweets:\n",
    "                break\n",
    "\n",
    "        df = pd.DataFrame({'user': user_data, 'text': text_data, 'time': time_data})\n",
    "        df.to_csv(output, index=False)\n",
    "        print(f\"Total {current_tweets} tweets scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_twitter_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting tweet: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\".//div[@lang]\"}\n",
      "  (Session info: chrome-headless-shell=125.0.6422.112); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF726B11F22+60322]\n",
      "\t(No symbol) [0x00007FF726A8CE99]\n",
      "\t(No symbol) [0x00007FF726947EBA]\n",
      "\t(No symbol) [0x00007FF726997676]\n",
      "\t(No symbol) [0x00007FF72699773C]\n",
      "\t(No symbol) [0x00007FF72698AEEC]\n",
      "\t(No symbol) [0x00007FF7269BC25F]\n",
      "\t(No symbol) [0x00007FF72698ADB6]\n",
      "\t(No symbol) [0x00007FF7269BC430]\n",
      "\t(No symbol) [0x00007FF7269DBC80]\n",
      "\t(No symbol) [0x00007FF7269BBFC3]\n",
      "\t(No symbol) [0x00007FF726989617]\n",
      "\t(No symbol) [0x00007FF72698A211]\n",
      "\tGetHandleVerifier [0x00007FF726E2946D+3301613]\n",
      "\tGetHandleVerifier [0x00007FF726E73693+3605267]\n",
      "\tGetHandleVerifier [0x00007FF726E69410+3563664]\n",
      "\tGetHandleVerifier [0x00007FF726BC42F6+790390]\n",
      "\t(No symbol) [0x00007FF726A974DF]\n",
      "\t(No symbol) [0x00007FF726A933D4]\n",
      "\t(No symbol) [0x00007FF726A93562]\n",
      "\t(No symbol) [0x00007FF726A82F6F]\n",
      "\tBaseThreadInitThunk [0x00007FFD6337257D+29]\n",
      "\tRtlUserThreadStart [0x00007FFD64CEAA48+40]\n",
      "\n",
      "Scraped 7 tweets\n",
      "Scraped 13 tweets\n",
      "Scraped 19 tweets\n",
      "Scraped 25 tweets\n",
      "Scraped 31 tweets\n",
      "Scraped 37 tweets\n",
      "Scraped 43 tweets\n",
      "Scraped 49 tweets\n",
      "Scraped 55 tweets\n",
      "Scraped 61 tweets\n",
      "Scraped 67 tweets\n",
      "Scraped 73 tweets\n",
      "Scraped 79 tweets\n",
      "Scraped 85 tweets\n",
      "Scraped 91 tweets\n",
      "Scraped 97 tweets\n",
      "Scraped 103 tweets\n",
      "Total 103 tweets scraped\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
